{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZbR2ZT9G2Fw"
      },
      "outputs": [],
      "source": [
        "#                                                                            \n",
        "#    Copyright 2022\n",
        "#    Alexander Belyi <alexander.belyi@gmail.com>,\n",
        "#    Stanislav Sobolevsky <sobolevsky@nyu.edu>                                               \n",
        "#                                                                            \n",
        "#    This file contains the source code of the GNNS algorithm and its evaluation.\n",
        "#\n",
        "#    This program is free software: you can redistribute it and/or modify\n",
        "#    it under the terms of the GNU General Public License as published by\n",
        "#    the Free Software Foundation, either version 3 of the License, or\n",
        "#    (at your option) any later version.\n",
        "#\n",
        "#    This program is distributed in the hope that it will be useful,\n",
        "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "#    GNU General Public License for more details.\n",
        "#\n",
        "#    You should have received a copy of the GNU General Public License\n",
        "#    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuiRqBvbv9Ik"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# data = pd.read_csv('./Colab Notebooks/musae_ENGB_edges.csv')\n",
        "# print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CutCrYZ0BzZM",
        "outputId": "7ac8c2c9-31a4-4a2a-ba84-acf1bb3b8fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GNNS' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Alexander-Belyi/GNNS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h2qzaJTe9B_",
        "outputId": "c49e4b9f-2fb7-48d7-8cdb-fade0fc6393e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycombo in /usr/local/lib/python3.8/dist-packages (0.1.7)\n",
            "Requirement already satisfied: pybind11<3.0.0,>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from pycombo) (2.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: leidenalg in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
            "Requirement already satisfied: igraph<0.11,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from leidenalg) (0.10.2)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from igraph<0.11,>=0.10.0->leidenalg) (1.6.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cdlib in /usr/local/lib/python3.8/dist-packages (0.2.6)\n",
            "Requirement already satisfied: python-louvain>=0.16 in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.21.6)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.8/dist-packages (from cdlib) (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from cdlib) (4.64.1)\n",
            "Requirement already satisfied: dynetx in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.3.1)\n",
            "Requirement already satisfied: thresholdclustering in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.1)\n",
            "Requirement already satisfied: bimlpa in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.1.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.11.2)\n",
            "Requirement already satisfied: demon in /usr/local/lib/python3.8/dist-packages (from cdlib) (2.0.6)\n",
            "Requirement already satisfied: pyclustering in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.10.1.2)\n",
            "Requirement already satisfied: chinese-whispers in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.8.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.29.32)\n",
            "Requirement already satisfied: markov-clustering in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.0.6.dev0)\n",
            "Requirement already satisfied: nf1 in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.0.4)\n",
            "Requirement already satisfied: eva-lcd in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.1.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.8/dist-packages (from cdlib) (2.6.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from cdlib) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.16.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.6.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.20.8)\n",
            "Requirement already satisfied: python-igraph in /usr/local/lib/python3.8/dist-packages (from cdlib) (0.10.2)\n",
            "Requirement already satisfied: angel-cd in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from cdlib) (1.0.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from dynetx->cdlib) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->cdlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->cdlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->cdlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->cdlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->cdlib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->cdlib) (2022.6)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch->cdlib) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch->cdlib) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from pooch->cdlib) (21.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch->cdlib) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch->cdlib) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch->cdlib) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch->cdlib) (2022.9.24)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from pyclustering->cdlib) (7.1.2)\n",
            "Requirement already satisfied: igraph==0.10.2 in /usr/local/lib/python3.8/dist-packages (from python-igraph->cdlib) (0.10.2)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from igraph==0.10.2->python-igraph->cdlib) (1.6.7)\n",
            "Requirement already satisfied: Levenshtein==0.20.8 in /usr/local/lib/python3.8/dist-packages (from python-Levenshtein->cdlib) (0.20.8)\n",
            "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from Levenshtein==0.20.8->python-Levenshtein->cdlib) (2.13.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->cdlib) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->cdlib) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycombo\n",
        "!pip install leidenalg\n",
        "!pip install cdlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNcBYSybv5CP",
        "outputId": "9d6e1099-138c-473a-d1b3-6cfe0f9f438f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(r\"/content/drive/My Drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DWbhMGGfHIV"
      },
      "outputs": [],
      "source": [
        "import bz2\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy\n",
        "import networkx as nx\n",
        "import igraph as iGraph\n",
        "import leidenalg\n",
        "from pycombo import pyCombo\n",
        "from cdlib import algorithms, NodeClustering\n",
        "from multiprocessing import Pool\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx09T-zTGeB8",
        "outputId": "5f66f7c8-2abf-4a92-e778-05da1b5aedbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor: tensor([1., 2., 3., 4.])\n",
            "Tensor device: cpu\n",
            "CUDA GPU: True\n",
            "tensor([1., 2., 3., 4.], device='cuda:0')\n",
            "Tensor device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# create a tensor\n",
        "x = torch.tensor([1.0,2.0,3.0,4.0])\n",
        "print(\"Tensor:\", x)\n",
        "# check tensor device (cpu/cuda)\n",
        "print(\"Tensor device:\", x.device)\n",
        "# Move tensor from CPU to GPU\n",
        "# check CUDA GPU is available or not\n",
        "print(\"CUDA GPU:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "   x=x.to(\"cuda\")\n",
        "print(x)\n",
        "# now check the tensor device\n",
        "print(\"Tensor device:\", x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBnYIimzh1im"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Engine:\n",
        "    def __init__(self, engine: str) -> None:\n",
        "        if engine == 'np':\n",
        "            self.array = self.array_np\n",
        "            self.sparse_array = self.sparse_array_np\n",
        "            self.diag = self.diag_np\n",
        "            self.sum = self.sum_np\n",
        "            self.sparse_sum = self.sparse_sum_np\n",
        "            self.mean = self.mean_np\n",
        "            self.max = self.max_np\n",
        "            self.argmax = self.argmax_np\n",
        "            self.eye = self.eye_np\n",
        "            self.ones = self.ones_np\n",
        "            self.zeros = self.zeros_np\n",
        "            self.abs = self.abs_np\n",
        "            self.exp = self.exp_np\n",
        "            self.concatenate = self.concatenate_np\n",
        "            self.reshape = self.reshape_np\n",
        "            self.transpose = self.transpose_np\n",
        "            self.tile = self.tile_np\n",
        "            self.matmul = self.matmul_np\n",
        "            self.random_uniform = self.random_uniform_np\n",
        "            self.to_sparse_csr = self.to_sparse_csr_np\n",
        "            self.cuda = self.identity_np\n",
        "            self.numpy = self.identity_np\n",
        "        elif engine == 'torch':\n",
        "            self.device = torch.device('cpu')\n",
        "            self.cuda_available = False\n",
        "            if torch.cuda.is_available():\n",
        "                self.cuda_available = True\n",
        "                self.device = torch.device(0)\n",
        "            self.array = self.array_torch\n",
        "            self.sparse_array = self.sparse_array_torch\n",
        "            self.diag = self.diag_torch\n",
        "            self.sum = self.sum_torch\n",
        "            self.sparse_sum = self.sparse_sum_torch\n",
        "            self.mean = self.mean_torch\n",
        "            self.max = self.max_torch\n",
        "            self.argmax = self.argmax_torch\n",
        "            self.eye = self.eye_torch\n",
        "            self.ones = self.ones_torch\n",
        "            self.zeros = self.zeros_torch\n",
        "            self.abs = self.abs_torch\n",
        "            self.exp = self.exp_torch\n",
        "            self.concatenate = self.concatenate_torch\n",
        "            self.reshape = self.reshape_torch\n",
        "            self.transpose = self.transpose_torch\n",
        "            self.tile = self.tile_torch\n",
        "            self.matmul = self.matmul_torch\n",
        "            self.random_uniform = self.random_uniform_torch\n",
        "            self.to_sparse_csr = self.to_sparse_csr_torch\n",
        "            self.cuda = self.cuda_torch\n",
        "            self.numpy = self.numpy_torch\n",
        "\n",
        "    def array_np(self, x, device=None):\n",
        "        return np.array(x)\n",
        "\n",
        "    def sparse_array_np(self, x, device=None):\n",
        "        #if type(x) == scipy.sparse.csr_array: # requires python >= 3.8\n",
        "        if type(x) == scipy.sparse.csr_matrix:\n",
        "            return x\n",
        "        #return scipy.sparse.csr_array(x)\n",
        "        return scipy.sparse.csr_matrix(x)\n",
        "\n",
        "    def diag_np(self, x):\n",
        "        return np.diag(x)\n",
        "\n",
        "    def sum_np(self, x, axis=None, keepdims=False):\n",
        "        return np.sum(x, axis=axis, keepdims=keepdims)\n",
        "\n",
        "    def sparse_sum_np(self, x, axis=None):\n",
        "        return np.array(np.sum(x, axis=axis))\n",
        "\n",
        "    def mean_np(self, x, axis=None, keepdims=False):\n",
        "        return np.mean(x, axis=axis, keepdims=keepdims)\n",
        "    \n",
        "    def max_np(self, x, axis=None, keepdims=False):\n",
        "        return np.max(x, axis=axis, keepdims=keepdims)\n",
        "\n",
        "    def argmax_np(self, x, axis=None): \n",
        "        return np.argmax(x, axis=axis)\n",
        "\n",
        "    def eye_np(self, size, dtype=None, device=None):\n",
        "        return np.eye(size, dtype=dtype)\n",
        "\n",
        "    def ones_np(self, size, dtype=None, device=None):\n",
        "        return np.ones(size, dtype=dtype)\n",
        "\n",
        "    def zeros_np(self, size, dtype=None, device=None):\n",
        "        return np.zeros(size, dtype=dtype)\n",
        "\n",
        "    def abs_np(self, x):\n",
        "        return np.abs(x)\n",
        "\n",
        "    def exp_np(self, x):\n",
        "        return np.exp(x)\n",
        "\n",
        "    def concatenate_np(self, x, axis=None):\n",
        "        return np.concatenate(x, axis=axis)\n",
        "    \n",
        "    def reshape_np(self, x, shape):\n",
        "        return np.reshape(x, shape)\n",
        "\n",
        "    def transpose_np(self, x, axis1, axis2):\n",
        "        return np.swapaxes(x, axis1, axis2)\n",
        "\n",
        "    def tile_np(self, x, shape):\n",
        "        return np.tile(x, shape)\n",
        "\n",
        "    def matmul_np(self, x, y):\n",
        "        return np.matmul(x, y)\n",
        "\n",
        "    def random_uniform_np(self, low, high, size, device=\"cpu\"):\n",
        "        return np.random.uniform(low=low, high=high, size=size)\n",
        "\n",
        "    def to_sparse_csr_np(self, x):\n",
        "        return x.tocsr()\n",
        "\n",
        "    def identity_np(self, x):\n",
        "        return x\n",
        "\n",
        "    ### torch\n",
        "    def array_torch(self, x, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        return torch.tensor(x, device=device)\n",
        "\n",
        "    def sparse_array_torch(self, x, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        #coo_x = scipy.sparse.coo_array(x) # requires python >=3.8\n",
        "        coo_x = scipy.sparse.coo_matrix(x)\n",
        "        return torch.sparse_coo_tensor(np.vstack((coo_x.row, coo_x.col)), coo_x.data, size=coo_x.shape, device=device)\n",
        "\n",
        "    def diag_torch(self, x):\n",
        "        return torch.diag(x)\n",
        "\n",
        "    def sum_torch(self, x, axis=None, keepdims=False):\n",
        "        return torch.sum(x, axis=axis, keepdims=keepdims)\n",
        "\n",
        "    def sparse_sum_torch(self, x, axis=None):\n",
        "        return torch.sparse.sum(x, dim=axis).to_dense()\n",
        "\n",
        "    def mean_torch(self, x, axis=None, keepdims=False):\n",
        "        return torch.mean(x, axis=axis, keepdims=keepdims)\n",
        "    \n",
        "    def max_torch(self, x, axis=None, keepdims=False):\n",
        "        if axis is None:\n",
        "            return torch.max(x, axis=axis, keepdims=keepdims)\n",
        "        else:\n",
        "            return torch.max(x, axis=axis, keepdims=keepdims).values\n",
        "\n",
        "    def argmax_torch(self, x, axis=None, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        return torch.argmax(x, axis=axis).to(device)\n",
        "\n",
        "    def eye_torch(self, size, dtype=None, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        return torch.eye(size, dtype=dtype, device=device)\n",
        "\n",
        "    def ones_torch(self, size, dtype=None, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        return torch.ones(size, dtype=dtype, device=device)\n",
        "\n",
        "    def zeros_torch(self, size, dtype=None, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        return torch.zeros(size, dtype=dtype, device=device)\n",
        "\n",
        "    def abs_torch(self, x):\n",
        "        return torch.abs(x)\n",
        "\n",
        "    def exp_torch(self, x):\n",
        "        return torch.exp(x)\n",
        "\n",
        "    def concatenate_torch(self, x, axis=0):\n",
        "        return torch.cat(x, dim=axis)\n",
        "    \n",
        "    def reshape_torch(self, x, shape):\n",
        "        return torch.reshape(x, shape)\n",
        "\n",
        "    def transpose_torch(self, x, dim0, dim1):\n",
        "        return torch.transpose(x, dim0, dim1)\n",
        "\n",
        "    def tile_torch(self, x, shape):\n",
        "        return torch.tile(x, shape)\n",
        "\n",
        "    def matmul_torch(self, x, y):\n",
        "        return torch.matmul(x, y)\n",
        "\n",
        "    def random_uniform_torch(self, low, high, size, dtype=None, device=\"cpu\"):\n",
        "        if not self.cuda_available:\n",
        "            device = \"cpu\"\n",
        "        return torch.zeros(size, dtype=dtype, device=device).uniform_(low, high)\n",
        "\n",
        "    def to_sparse_csr_torch(self, x):\n",
        "        return x.to_sparse_csr()\n",
        "\n",
        "    def cuda_torch(self, x):\n",
        "        if not self.cuda_available:\n",
        "            return x\n",
        "        return x.cuda()\n",
        "    \n",
        "    def numpy_torch(self, x):\n",
        "        return x.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_FK0hhZfB4y"
      },
      "outputs": [],
      "source": [
        "def set_all_random_seeds(seed=1):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def get_modularity_matrix(G, symmetrize=True, loops_style=2, device=\"cpu\"):\n",
        "    '''build modularity matrix'''\n",
        "    A = nx.to_numpy_array(G)\n",
        "    A = eng.array(A, device)\n",
        "    if loops_style == 2 and not G.is_directed():\n",
        "        A += eng.diag(eng.diag(A))\n",
        "    elif loops_style == 0:\n",
        "        A -= eng.diag(eng.diag(A))\n",
        "    w_in = A.sum(axis=0, keepdims=True)\n",
        "    w_out = A.sum(axis=1, keepdims=True)\n",
        "    T = w_out.sum()\n",
        "    Q = A / T - w_out @ w_in / (T ** 2)\n",
        "    if symmetrize:\n",
        "        Q = (Q + Q.T) / 2\n",
        "    return Q\n",
        "\n",
        "def get_sparse_modularity_matrix(G, loops_style=2, device=\"cpu\"):\n",
        "    '''build sparse modularity matrix'''\n",
        "    #A = nx.to_scipy_sparse_array(G, format=\"coo\") #requires python >= 3.8\n",
        "    A = nx.to_scipy_sparse_matrix(G, dtype=float, format=\"coo\")\n",
        "    if loops_style == 2 and not G.is_directed():\n",
        "        A.setdiag(A.diagonal() * 2)\n",
        "    elif loops_style == 0:\n",
        "        A.setdiag(0)\n",
        "    Q_diag = eng.array(A.diagonal(), device)\n",
        "    A = eng.sparse_array(A, device)\n",
        "    w_in = eng.sparse_sum(A, axis=0).reshape((1, A.shape[0]))\n",
        "    w_out = eng.sparse_sum(A, axis=1).reshape((A.shape[0], 1))\n",
        "    T = w_out.sum()\n",
        "    w_in /= T\n",
        "    w_out /= T\n",
        "    Q = A / T\n",
        "    Q_diag /= T\n",
        "    Q = eng.to_sparse_csr(Q)\n",
        "    # Q -= w_out @ w_in\n",
        "    return Q, Q_diag, w_out, w_in\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMt1naxFiHsV"
      },
      "outputs": [],
      "source": [
        "class GNNSModularityOptimizer():\n",
        "    def __init__(self, G, strip_diagonal=True, normalize_modularity=False,\n",
        "                 normalize_each_step=True, normalize_QC=True, use_sparse=False):\n",
        "        self.num_model_params = 2\n",
        "        self.net_size = len(G)\n",
        "        self.normalize_modularity = normalize_modularity\n",
        "        self.use_sparse = use_sparse\n",
        "        #strip diagonal elements of the modularity matrix when initializing the data\n",
        "        self.strip_diagonal = strip_diagonal\n",
        "        if self.use_sparse:\n",
        "            self.sparse_Q, self.Q_diag, self.w_out, self.w_in = get_sparse_modularity_matrix(G, device=\"cuda:0\")\n",
        "            self.Q_diag = eng.reshape(self.Q_diag, (1, self.net_size, 1))\n",
        "            self.Q_diag -= eng.reshape(self.w_out * eng.transpose(self.w_in, 0, 1), (1, self.net_size, 1))\n",
        "        else:\n",
        "            self.Q = get_modularity_matrix(G, symmetrize=True, device=\"cuda:0\")\n",
        "            self.Q_diag = eng.reshape(eng.diag(self.Q), (1, self.net_size, 1))\n",
        "        self.reshape_Q()\n",
        "        self.normalize_each_step = normalize_each_step\n",
        "        self.normalize_QC = normalize_QC\n",
        "\n",
        "    def reshape_Q(self):\n",
        "        if self.use_sparse:\n",
        "            self.w_out = self.w_out[None, :, :]\n",
        "            self.w_in = self.w_in[None, :, :]\n",
        "        else:\n",
        "            self.Q = self.Q.reshape((1, *self.Q.shape)) # add batch dimension\n",
        "            if self.normalize_modularity:\n",
        "                w = eng.sum(eng.abs(self.Q), axis=2, keepdims=True)\n",
        "                self.Q /= w + (w==0)\n",
        "\n",
        "    def reshape_model_params(self, params):\n",
        "        f0 = eng.cuda(-params[:, 0:1, None])\n",
        "        f1 = eng.cuda(params[:, 1:2, None])\n",
        "        f2 = 1.0 - f0 - f1\n",
        "        return f0, f1, f2\n",
        "\n",
        "    def discretize(self):\n",
        "        c = eng.argmax(self.C, axis=2)\n",
        "        self.C[:,:,:] = 0\n",
        "        for i in range(self.batch_size):\n",
        "            self.C[i, range(self.net_size), c[i, :]] = 1\n",
        "\n",
        "    def calculate_modularity(self):\n",
        "        QxC = self.Q_times_C(False)\n",
        "        q = eng.matmul(self.C.reshape((self.batch_size, 1, -1)), QxC.reshape((self.batch_size, -1, 1))).reshape((-1,))\n",
        "        return q\n",
        "\n",
        "    def activation(self,x): #ReLU\n",
        "        return x * (x>0)\n",
        "\n",
        "    def Q_times_C(self, strip_diagonal):\n",
        "        if self.use_sparse:\n",
        "            # Stack the vector batch into columns. (b, n, k) -> (n, b, k) -> (n, b*k)\n",
        "            C = eng.transpose(self.C, 0, 1).reshape((self.net_size, -1))\n",
        "            # And then reverse the reshaping. (n, n) x (n, b*k) = (n, b*k) -> (n, b, k) -> (b, n, k)\n",
        "            QxC = eng.transpose((self.sparse_Q @ C).reshape((self.net_size, self.batch_size, -1)), 1, 0)\n",
        "            QxC -= eng.matmul(self.w_out, eng.matmul(self.w_in, self.C))\n",
        "        else:\n",
        "            QxC = eng.matmul(self.Q, self.C)\n",
        "        if strip_diagonal:\n",
        "            return QxC - self.Q_diag * self.C\n",
        "        else:\n",
        "            return QxC\n",
        "\n",
        "    def calculate(self, params, init_partition, num_iterations, discretize_result=False):\n",
        "        self.batch_size = init_partition.shape[0] # number of random starting configurations\n",
        "        f0, f1, f2 = self.reshape_model_params(params)\n",
        "        # C.shape = batch_size x net_size x num_communities\n",
        "        self.C = init_partition\n",
        "        self.normalize_attachments()\n",
        "        for _ in range(num_iterations):\n",
        "            QxC = self.Q_times_C(self.strip_diagonal)\n",
        "            if self.normalize_QC: #normalize by max QxC\n",
        "                t = eng.abs(eng.max(QxC, axis=2, keepdims=True))\n",
        "                QxC /= t + (t == 0)\n",
        "            bias = eng.ones((self.batch_size, self.net_size, 1), dtype=float, device=\"cuda:0\")\n",
        "            next_C = f0 * bias + f1 * self.C + f2 * QxC\n",
        "            self.C = self.activation(next_C)\n",
        "            self.normalize_attachments()\n",
        "        if discretize_result:\n",
        "            self.discretize()\n",
        "        mod = self.calculate_modularity()\n",
        "        return self.C, mod\n",
        "\n",
        "    def normalize_attachments(self):\n",
        "        if self.normalize_each_step:\n",
        "            w = eng.sum(self.C, axis=2, keepdims=True)\n",
        "            self.C /= w + (w==0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZp2RzmNiMcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def runGNNSSeries(G, max_num_communities, iterations_per_stage, num_random_configs, fraction_to_keep,\n",
        "                discretize_last=True, init_params=None, init_communities=None, alpha=0.0, manual_gc=True, verbose=0):\n",
        "    num_model_params = 2\n",
        "    net_size = len(G)\n",
        "    max_batch_size = hypers.get('max_batch_size', 1000)\n",
        "    max_total_tensor_size = hypers.get('max_total_tensor_size', 200_000_000)\n",
        "    max_batch_size = max(1, min(max_batch_size, int(max_total_tensor_size / (net_size * max_num_communities))))\n",
        "    #print('net_size', net_size,\n",
        "    #      'max_num_communities =', max_num_communities,\n",
        "    #      'num_random_configs =', num_random_configs,\n",
        "    #      'max_batch_size =', max_batch_size,\n",
        "    #      'net_size * max_num_communities =',\n",
        "    #      net_size * max_num_communities)\n",
        "    start_time = time.time()\n",
        "    GNNS = GNNSModularityOptimizer(G, strip_diagonal=hypers.get('strip_diagonal', True),\n",
        "                                    normalize_modularity=hypers.get('normalize_modularity', False),\n",
        "                                    normalize_each_step=hypers.get('normalize_each_step', True),\n",
        "                                    use_sparse=hypers.get('use_sparse', False))\n",
        "    final_modularities = np.empty(0)\n",
        "    best_modularity = -1\n",
        "    # if num_random_configs is too large, do calculations in chunks\n",
        "    for i in range((num_random_configs + max_batch_size - 1) // max_batch_size):\n",
        "        cur_range = (i * max_batch_size, min((i + 1) * max_batch_size, num_random_configs))\n",
        "        batch_size = cur_range[1] - cur_range[0]\n",
        "        if init_params is None:\n",
        "            params = eng.random_uniform(low=0, high=1.0, size=(batch_size, num_model_params), device=\"cuda:0\")\n",
        "        else:\n",
        "            params = eng.tile(init_params.flatten(), (batch_size, 1))\n",
        "        if init_communities is None:\n",
        "            partition = eng.random_uniform(low=0, high=1.0, size=(batch_size, len(G), max_num_communities), device=\"cuda:0\")\n",
        "        else:\n",
        "            partition = eng.tile(init_communities, (batch_size, 1, 1))\n",
        "        for stage in range(len(iterations_per_stage)):\n",
        "            discretize = discretize_last and (stage == len(iterations_per_stage) - 1)\n",
        "            communities, modularities = GNNS.calculate(params, partition, iterations_per_stage[stage], discretize_result=discretize)\n",
        "            \n",
        "            modularities = eng.numpy(modularities)\n",
        "            index_best = np.argmax(modularities)\n",
        "            if verbose > 0:\n",
        "                print('Stage {} completed'.format(stage+1))\n",
        "                print('Top modularity={}, mean={}, best_parameters={}'.format(modularities[index_best], np.mean(modularities), params[index_best]))\n",
        "            if stage < len(iterations_per_stage) - 1:\n",
        "                next_batch_size = max(1, batch_size * iterations_per_stage[0] // iterations_per_stage[stage+1])\n",
        "                selected_indices = modularities >= sorted(modularities)[-max(1, int(next_batch_size * fraction_to_keep))]\n",
        "                params = params[selected_indices, :]\n",
        "                # initialize with best partitions while keeping initial model params\n",
        "                partition = communities[selected_indices]\n",
        "                num_to_keep = sum(selected_indices)\n",
        "                num_to_repeat = next_batch_size - num_to_keep\n",
        "                if num_to_repeat > 0:\n",
        "                    # some king of soft-max; uniform for alpha=0\n",
        "                    weights = np.exp(modularities[selected_indices] * alpha)\n",
        "                    weights = weights / sum(weights)\n",
        "                    indices_to_repeat_partition = np.random.choice(num_to_keep, size=num_to_repeat, p=weights)\n",
        "                    repeated_partition = partition[indices_to_repeat_partition]\n",
        "                    partition = eng.concatenate([partition, repeated_partition], axis=0) # we copy initial partitions with best modularities\n",
        "                    # old way:\n",
        "                    #indices_to_repeat_params = np.random.choice(num_to_keep, size=num_to_repeat, p=weights)\n",
        "                    #repeated_params = params[indices_to_repeat_params, :num_model_params] # randomly permute repeated params\n",
        "                    #params = eng.concatenate([params, repeated_params], axis=0)\n",
        "                    new_params = eng.random_uniform(low=0, high=1.0, size=(num_to_repeat, num_model_params), device=\"cuda:0\")\n",
        "                    params = eng.concatenate([params, new_params], axis=0) # replace repeated params with random ones\n",
        "        final_modularities = np.concatenate([final_modularities, modularities])\n",
        "        #############\n",
        "        ############# communities here \n",
        "        #############\n",
        "        #############\n",
        "        #############\n",
        "        if modularities[index_best] > best_modularity:\n",
        "            best_modularity = modularities[index_best]\n",
        "            best_communities = communities[index_best, :]\n",
        "            # print(f'Best Comm1: ', best_communities)\n",
        "            # print(f'Best Comm2: ', len(best_communities))\n",
        "            # print(f'Best Comm3: ', len(best_communities[0]))\n",
        "            print(f'index best: ', index_best)\n",
        "            # max_value = 0\n",
        "            # for zzzz in range(0,7126):\n",
        "            #     for xxxx in range(0,22):\n",
        "            #         ##print(f'{best_communities[zzzz][xxxx]} ')\n",
        "            #         if best_communities[zzzz][xxxx] > max_value: max_value = best_communities[zzzz][xxxx]\n",
        "            # print(max_value)\n",
        "            #print(f'Best Comm3: ', len(list(best_communities)[0][0]))\n",
        "            best_parameters = params[index_best]\n",
        "        if manual_gc:\n",
        "            del params, partition\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "    if manual_gc:\n",
        "        del GNNS\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    return best_communities, modularities, best_parameters, best_modularity, time.time()-start_time, index_best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsmYewmrzQCo"
      },
      "outputs": [],
      "source": [
        "\n",
        "def apply_method(arg):\n",
        "    G, weight_attr, method, seed = arg\n",
        "    modularity = -1\n",
        "    start_time = time.time()\n",
        "    if method == 'combo':\n",
        "        partition, modularity = pyCombo.execute(G, random_seed=seed)\n",
        "        partition_sets = {comm: set() for comm in partition.values()}\n",
        "        for node, comm in partition.items():\n",
        "            partition_sets[comm].add(node)\n",
        "        cdlib_comms = NodeClustering([list(c) for c in partition_sets.values()], G, \"Combo\", method_parameters={})\n",
        "    elif method == 'leiden':\n",
        "        partition = leidenalg.find_partition(G, leidenalg.ModularityVertexPartition, weights=weight_attr, n_iterations=-1, seed=seed)\n",
        "        cdlib_comms = NodeClustering([G.vs[x][\"_nx_name\"] for x in partition], G, \"Leiden\", method_parameters={})\n",
        "    elif method == 'leiden_ig':\n",
        "        partition = G.community_leiden(weights=weight_attr, objective_function=\"modularity\", n_iterations=-1)\n",
        "        cdlib_comms = NodeClustering([G.vs[x][\"_nx_name\"] for x in partition], G, \"Leiden_ig\", method_parameters={})\n",
        "    elif method == 'louvain':\n",
        "        cdlib_comms = algorithms.louvain(G)\n",
        "    elif method == 'louvain_ig':\n",
        "        partition = G.community_multilevel(weights=weight_attr)\n",
        "        cdlib_comms = NodeClustering([G.vs[x][\"_nx_name\"] for x in partition], G, \"Luvain_ig\", method_parameters={})\n",
        "        modularity = partition.modularity\n",
        "    elif method == 'belief':\n",
        "        cdlib_comms = algorithms.belief(G)\n",
        "    elif method ==  'eigenvector':\n",
        "        partition = G.community_leading_eigenvector()\n",
        "        cdlib_comms = NodeClustering([G.vs[x][\"_nx_name\"] for x in partition], G, \"Eigenvector\", method_parameters={})\n",
        "        modularity = partition.modularity\n",
        "    elif method ==  'greedy_modularity':\n",
        "        cdlib_comms = algorithms.greedy_modularity(G)\n",
        "    elif method ==  'greedy_modularity_ig':\n",
        "        partition = G.community_fastgreedy().as_clustering()\n",
        "        cdlib_comms = NodeClustering([G.vs[x][\"_nx_name\"] for x in partition], G, \"CNM\", method_parameters={})\n",
        "        modularity = partition.modularity\n",
        "    elif method ==  'spinglass':\n",
        "        try:\n",
        "            partition = G.community_spinglass()\n",
        "            cdlib_comms = NodeClustering([G.vs[x][\"_nx_name\"] for x in partition], G, \"Spinglass\", method_parameters={})\n",
        "            modularity = partition.modularity\n",
        "        except:\n",
        "            cdlib_comms = NodeClustering([[0] * len(G.vs)], G, \"Spinglass\", method_parameters={})\n",
        "            modularity = 0\n",
        "    return cdlib_comms, modularity, time.time() - start_time\n",
        "\n",
        "def is_igraph_method(method):\n",
        "    return method == 'leiden' or method == 'leiden_ig' or method == 'louvain_ig' or method == 'eigenvector' or method == 'spinglass' or method == 'greedy_modularity_ig'\n",
        "\n",
        "def is_deterministic(method):\n",
        "    return method == 'greedy_modularity' or method == 'greedy_modularity_ig'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRQCI1-viOVq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def partitionSeries(G, method, num_runs=10, verbose=0):\n",
        "    if num_runs > 0:\n",
        "        if is_deterministic(method):\n",
        "            num_runs = 1\n",
        "        partition = None\n",
        "        best_mod = -1\n",
        "        total_time = 0\n",
        "        results = eng.zeros((num_runs, 2)) # (mod, num_comms) pairs\n",
        "        graph = G\n",
        "        weight_attr = None\n",
        "        if is_igraph_method(method):\n",
        "            graph = iGraph.Graph.from_networkx(G)\n",
        "            if nx.is_weighted(G):\n",
        "                weight_attr = 'weight'\n",
        "        for i in range(num_runs):\n",
        "            cdlib_comms, modularity, elapsed_time = apply_method((graph, weight_attr, method, hypers['seed']+i))\n",
        "            if is_igraph_method(method):\n",
        "                cdlib_comms.graph = G\n",
        "            total_time += elapsed_time\n",
        "            if modularity == -1:\n",
        "                results[i, 0] = cdlib_comms.newman_girvan_modularity().score\n",
        "            else:\n",
        "                results[i, 0] = modularity\n",
        "            results[i, 1] = len(cdlib_comms.communities)\n",
        "            if best_mod < results[i, 0]:\n",
        "                best_mod = results[i, 0]\n",
        "                partition = cdlib_comms\n",
        "            if verbose > 1:\n",
        "                print(method + \"   mod_cdlib:\", results[i, 0])\n",
        "        max_mod_index = eng.argmax(results[:, 0])\n",
        "        if verbose > 0:\n",
        "            print('Best ' + method + ' modularity={}; {} communities'.format(results[max_mod_index, 0], results[max_mod_index, 1]))\n",
        "        res = {'best': results[max_mod_index, 0],\n",
        "               'best1': results[0, 0],\n",
        "               'best5': max(results[:5, 0]),\n",
        "               'best10': max(results[:10, 0]),\n",
        "               'best20': max(results[:20, 0]),\n",
        "               'min': results[:, 0].min(),\n",
        "               'mean': results[:, 0].mean(),\n",
        "               'comm_number': int(results[max_mod_index, 1]),\n",
        "               'partition': partition,\n",
        "               'total_time': total_time,\n",
        "               'avg_time': total_time / num_runs}\n",
        "    else:\n",
        "        res = {}\n",
        "    return res\n",
        "\n",
        "def partitionSeries_parallel(G, method, num_runs=10, verbose=0):\n",
        "    if num_runs > 0:\n",
        "        if is_deterministic(method):\n",
        "            num_runs = 1\n",
        "        partition = None\n",
        "        best_mod = -1\n",
        "        total_time = 0\n",
        "        results = eng.zeros((num_runs, 2)) # (mod, num_comms) pairs\n",
        "        graph = G\n",
        "        weight_attr = None\n",
        "        if is_igraph_method(method):\n",
        "            graph = iGraph.Graph.from_networkx(G)\n",
        "            if nx.is_weighted(G):\n",
        "                weight_attr = 'weight'\n",
        "        with Pool(hypers[\"num_processes\"]) as pool:\n",
        "            imap_unordered_it = pool.imap_unordered(apply_method,\n",
        "                                                    [(graph, weight_attr, method, hypers['seed']+i) for i in range(num_runs)],\n",
        "                                                    chunksize=hypers[\"num_processes\"])\n",
        "            i = 0\n",
        "            for res in imap_unordered_it:\n",
        "                cdlib_comms, modularity, elapsed_time = res\n",
        "                if is_igraph_method(method):\n",
        "                    cdlib_comms.graph = G\n",
        "                total_time += elapsed_time\n",
        "                if modularity == -1:\n",
        "                    results[i, 0] = cdlib_comms.newman_girvan_modularity().score\n",
        "                else:\n",
        "                    results[i, 0] = modularity\n",
        "                results[i, 1] = len(cdlib_comms.communities)\n",
        "                if best_mod < results[i, 0]:\n",
        "                    best_mod = results[i, 0]\n",
        "                    partition = cdlib_comms\n",
        "                if verbose > 1:\n",
        "                    print(method + \"   mod_cdlib:\", results[i, 0])\n",
        "                i += 1\n",
        "        max_mod_index = eng.argmax(results[:, 0])\n",
        "        if verbose > 0:\n",
        "            print('Best ' + method + ' modularity={}; {} communities'.format(results[max_mod_index, 0], results[max_mod_index, 1]))\n",
        "        res = {'best': results[max_mod_index, 0],\n",
        "               'best1': results[0, 0],\n",
        "               'best5': max(results[:5, 0]),\n",
        "               'best10': max(results[:10, 0]),\n",
        "               'best20': max(results[:20, 0]),\n",
        "               'min': results[:, 0].min(),\n",
        "               'mean': results[:, 0].mean(),\n",
        "               'comm_number': int(results[max_mod_index, 1]),\n",
        "               'partition': partition,\n",
        "               'total_time': total_time,\n",
        "               'avg_time': total_time / num_runs}\n",
        "    else:\n",
        "        res = {}\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vy8TrY6piRoN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def processNet(G, methods, num_runs=20, nums_initial_GNNS_configs=(100), verbose=0):\n",
        "    if num_runs > 0:\n",
        "        results = {}\n",
        "        comm_number = 0\n",
        "        best_mod = -1\n",
        "        for method in methods:\n",
        "            #results[method] = partitionSeries_parallel(G, num_runs=num_runs, method=method, verbose=verbose - 1)\n",
        "            results[method] = partitionSeries(G, num_runs=num_runs, method=method, verbose=1)\n",
        "            if best_mod < results[method].get('best', 0):\n",
        "                best_mod = results[method].get('best', 0)\n",
        "                comm_number = max(comm_number, results[method].get('comm_number', 0))\n",
        "                print(f'***COMM NUM***{comm_number}\\n')\n",
        "            if verbose == 1:\n",
        "                print(method + ' modularity best/best1/best5/best10/best20 = {:.6f}/{:.6f}/{:.6f}/{:.6f}/{:.6f}; min/avg = {:.6f}/{:.6f}; {} comm; time total/avg {:.2f}/{:.2f}'.format(\n",
        "                                    results[method].get('best', 0),\n",
        "                                    results[method].get('best1', 0),\n",
        "                                    results[method].get('best5', 0),\n",
        "                                    results[method].get('best10', 0),\n",
        "                                    results[method].get('best20', 0),\n",
        "                                    results[method].get('min', 0),\n",
        "                                    results[method].get('mean', 0),\n",
        "                                    results[method].get('comm_number', 0),\n",
        "                                    results[method].get('total_time', 0),\n",
        "                                    results[method].get('avg_time', 0)))\n",
        "            if verbose == 2:\n",
        "                print(method + 'Num Communities: {}'.format(results[method].get('comm_number', 0)))\n",
        "        if comm_number <= 0:\n",
        "            comm_number = 50\n",
        "        comm_number = min(comm_number, 50)\n",
        "        GNN = {}\n",
        "        for num_initial_GNNS_configs in nums_initial_GNNS_configs:\n",
        "            set_all_random_seeds(hypers['seed'])\n",
        "            iterations_per_stage = [10, 10, 30]\n",
        "            if num_initial_GNNS_configs >= 1_000:\n",
        "                iterations_per_stage += [100]\n",
        "            if num_initial_GNNS_configs >= 10_000:\n",
        "                iterations_per_stage += [350]\n",
        "            fraction_to_keep = 1/3 #proportion of best configs to move to the next stage\n",
        "            C, _, best_params, best_mod, GNNS_time, num_com = runGNNSSeries(G, max_num_communities = comm_number + 1,\n",
        "                                                    iterations_per_stage=iterations_per_stage,\n",
        "                                                    num_random_configs=num_initial_GNNS_configs,\n",
        "                                                    fraction_to_keep=fraction_to_keep,\n",
        "                                                    manual_gc=(len(G) > 1000),\n",
        "                                                    verbose=verbose-1)\n",
        "            GNN[num_initial_GNNS_configs] = {'mod':best_mod,\n",
        "                                             'best_params':best_params,\n",
        "                                             'partition': C.argmax(axis=1),\n",
        "                                             'total_time': GNNS_time,\n",
        "                                             'num_comms': num_com}\n",
        "            if verbose > 0:\n",
        "                print('GNN{} modularity = {}; best params = {}; num_comm = {} -- partition = {} -- maybe coms = {} -- par length = {}'.format(num_initial_GNNS_configs, GNN[num_initial_GNNS_configs]['mod'], GNN[num_initial_GNNS_configs]['best_params'], GNN[num_initial_GNNS_configs]['num_comms'],GNN[num_initial_GNNS_configs]['partition'], torch.max(GNN[num_initial_GNNS_configs]['partition']), (len((GNN[num_initial_GNNS_configs]['partition']))) ))\n",
        "                print(f'mods: {_}\\n')\n",
        "                print(f'C: {C}\\n')\n",
        "        #latex table output\n",
        "        print(' & '.join([G.name,\n",
        "                        ' & '.join(['%.6f' % results[method].get('best',0) for method in methods]),\n",
        "                        ' & '.join(['%.6f' % GNN[v].get('mod',0) for v in nums_initial_GNNS_configs]),\n",
        "                        ' & '.join(['%.2f' % results[method].get('total_time',0) for method in methods]),\n",
        "                        ' & '.join(['%.2f' % GNN[v].get('total_time',0) for v in nums_initial_GNNS_configs])\n",
        "                        ]))\n",
        "        return results, GNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQioByakydsG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_graph(name, make_undirected=True, remove_weights=False, verbose=0):\n",
        "    if name[-4:] == \".net\":\n",
        "        G = nx.read_pajek(hypers['path_classic'] + name)\n",
        "        G.name = name[:-4]\n",
        "    elif name[-10:] == \".graph.bz2\":\n",
        "        with bz2.open(hypers['path_classic'] + name) as f:\n",
        "            G = nx.DiGraph()\n",
        "            i = 0\n",
        "            n = 0\n",
        "            m = 0\n",
        "            fmt = 0\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if len(line) == 0:\n",
        "                    if i > 0:\n",
        "                        i += 1\n",
        "                elif line[0] != '%':\n",
        "                    values = [int(x) for x in line.split()]\n",
        "                    if i == 0:\n",
        "                        n, m = values[:2]\n",
        "                        if len(values) > 2:\n",
        "                            fmt = values[2]\n",
        "                        if fmt > 1:\n",
        "                            print(\"Error in file: \", name, \" unsupported format!\")\n",
        "                            break\n",
        "                        G.add_nodes_from(range(n))\n",
        "                    else:\n",
        "                        if fmt == 0:\n",
        "                            G.add_edges_from([(i-1, j-1) for j in values])\n",
        "                        elif fmt == 1:\n",
        "                            G.add_weighted_edges_from([(i-1, j-1, w) for j, w in zip(values[::2], values[1::2])])\n",
        "                    i += 1\n",
        "        G.name = name[:-10]\n",
        "    num_selfloops = len(list(nx.selfloop_edges(G)))\n",
        "    if num_selfloops > 0:\n",
        "        print(name, \" self-loops: \", num_selfloops)\n",
        "    A = nx.to_scipy_sparse_matrix(G)\n",
        "    is_weighted = len(np.unique(A.data)) > 2 #there are values other than 0 and 1\n",
        "    is_directed = np.abs((A - A.transpose()).data).sum() > 1e-10\n",
        "    if remove_weights:\n",
        "        G = nx.from_scipy_sparse_matrix(A > 0)\n",
        "    if make_undirected or not is_directed:\n",
        "        G = nx.Graph(G)\n",
        "    if verbose > 0:\n",
        "        print('{} of size {}, with {} edges, directed = {}, weighted = {}, #self-loops = {}'.format(\n",
        "            name, len(G), G.number_of_edges(), is_directed, is_weighted, num_selfloops))\n",
        "    del A\n",
        "    gc.collect()\n",
        "    return G\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m444fVH6NdAR"
      },
      "outputs": [],
      "source": [
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "hypers = {}\n",
        "hypers['path_classic'] = './GNNS/networks/'\n",
        "\n",
        "#hypers['ENGINE'] = 'np'\n",
        "hypers['ENGINE'] = 'torch'\n",
        "eng = Engine(hypers['ENGINE'])\n",
        "\n",
        "hypers['seed'] = 13\n",
        "hypers['strip_diagonal'] = True\n",
        "hypers['normalize_modularity'] = False\n",
        "hypers['normalize_each_step'] = True\n",
        "hypers['use_sparse'] = True\n",
        "hypers['max_batch_size'] = 1000\n",
        "hypers['max_total_tensor_size'] = 100_000_000\n",
        "hypers[\"num_processes\"] = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bl1jcmRf9Ij",
        "outputId": "b2af8c7a-3de9-41ab-9822-25098aec4ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Network & louvain_ig_mod & GNN100_mod & GNN2500_mod & louvain_ig_time & GNN100_time & GNN2500_time\n",
            "edges_pajek_large.net\n",
            "\n",
            "Best louvain_ig modularity=0.4242241604059415; 20.0 communities\n",
            "***COMM NUM***20\n",
            "\n",
            "louvain_ig modularity best/best1/best5/best10/best20 = 0.424224/0.422692/0.424224/0.424224/0.424224; min/avg = 0.418866/0.422060; 20 comm; time total/avg 269.55/26.96\n",
            "index best:  8\n",
            "index best:  0\n",
            "GNN100 modularity = 0.4229706264260892; best params = tensor([0.6380, 0.2022], device='cuda:0'); num_comm = 0 -- partition = tensor([ 4, 10, 19,  ...,  4, 10, 10], device='cuda:0') -- maybe coms = 20 -- par length = 168114\n",
            "mods: [0.42297063 0.42000834 0.42012566 0.42000929 0.42161331]\n",
            "\n",
            "C: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
            "\n",
            "index best:  1\n",
            "index best:  1\n",
            "index best:  1\n",
            "index best:  0\n",
            "GNN2500 modularity = 0.4249331799487486; best params = tensor([0.8563, 0.4264], device='cuda:0'); num_comm = 0 -- partition = tensor([19, 13, 13,  ..., 19, 13, 18], device='cuda:0') -- maybe coms = 20 -- par length = 168114\n",
            "mods: [0.41587634]\n",
            "\n",
            "C: tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.]], device='cuda:0')\n",
            "\n",
            " & 0.424224 & 0.422971 & 0.424933 & 269.55 & 93.60 & 1648.41\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth',7000)\n",
        "def get_real_world_nets_small():\n",
        "    network_file_names = [\n",
        "        \"de.net\",\n",
        "        \"engb.net\",\n",
        "        \"es.net\",\n",
        "        \"fr.net\",\n",
        "        \"ptbr.net\",\n",
        "        \"ru.net\",\n",
        "        \"large.net\"\n",
        "    ]\n",
        "    return network_file_names\n",
        "\n",
        "def get_real_world_nets_big():\n",
        "    network_file_names = [\n",
        "        #\"power.graph.bz2\",\n",
        "        # \"PGPgiantcompo.graph.bz2\",\n",
        "        #\"krong500slogn16.graph.bz2\",\n",
        "    ]\n",
        "    return network_file_names\n",
        "\n",
        "def run_real_world_nets(big_nets=False):\n",
        "    network_file_names = get_real_world_nets_small()\n",
        "    if big_nets:\n",
        "        network_file_names = get_real_world_nets_big()\n",
        "    methods = ['louvain_ig'] #['leiden', 'louvain_ig']#, 'spinglass', 'greedy_modularity_ig']#, 'eigenvector', 'belief']\n",
        "    # if not big_nets:\n",
        "    #     methods += ['combo']\n",
        "    nums_initial_GNNS_configs = [100, 2500]\n",
        "    #latex table output\n",
        "    print(' & '.join(['Network', ' & '.join([method+'_mod' for method in methods]),\n",
        "                    ' & '.join(['GNN'+str(v)+'_mod' for v in nums_initial_GNNS_configs]),\n",
        "                    ' & '.join([method+'_time' for method in methods]),\n",
        "                    ' & '.join(['GNN'+str(v)+'_time' for v in nums_initial_GNNS_configs])]))\n",
        "    verbose = 0\n",
        "    for name in network_file_names:\n",
        "        print(f'{name}\\n')\n",
        "        if verbose > 0:\n",
        "            print(\"\\n\\n\\n\" + name)\n",
        "        G = read_graph(name, make_undirected=True,remove_weights=True)\n",
        "        processNet(G, methods, nums_initial_GNNS_configs=nums_initial_GNNS_configs, num_runs=10, verbose=1)\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "\n",
        "run_real_world_nets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b0kj_6NNzb",
        "outputId": "6e0c95da-82b8-4f1d-fee5-b83172fefbe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Network & louvain_ig_mod & GNN100_mod & GNN2500_mod & louvain_ig_time & GNN100_time & GNN2500_time\n",
            "edges_pajek_large.net\n",
            "\n",
            "Best louvain_ig modularity=0.4242241604059415; 20.0 communities\n",
            "***COMM NUM***20\n",
            "\n",
            "louvain_ig modularity best/best1/best5/best10/best20 = 0.424224/0.422692/0.424224/0.424224/0.424224; min/avg = 0.418866/0.422060; 20 comm; time total/avg 239.21/23.92\n",
            "index best:  8\n",
            "index best:  0\n",
            "GNN100 modularity = 0.4229706264260892; best params = tensor([0.6380, 0.2022], device='cuda:0'); num_comm = 0 -- partition = tensor([ 4, 10, 19,  ...,  4, 10, 10], device='cuda:0') -- maybe coms = 20 -- par length = 168114\n",
            "mods: [0.42297063 0.42000834 0.42012566 0.42000929 0.42161331]\n",
            "\n",
            "C: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
            "\n",
            "index best:  1\n",
            "index best:  1\n",
            "index best:  1\n",
            "index best:  0\n",
            "GNN2500 modularity = 0.4249331799487486; best params = tensor([0.8563, 0.4264], device='cuda:0'); num_comm = 0 -- partition = tensor([19, 13, 13,  ..., 19, 13, 18], device='cuda:0') -- maybe coms = 20 -- par length = 168114\n",
            "mods: [0.41587634]\n",
            "\n",
            "C: tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.]], device='cuda:0')\n",
            "\n",
            " & 0.424224 & 0.422971 & 0.424933 & 239.21 & 93.02 & 1640.85\n"
          ]
        }
      ],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "run_real_world_nets()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.11 ('Tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c2de701283e35bd4ebf557d6f0980a64018440651b26aa038bf25fa06e6b7f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
